<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Anqi (Angie) Liu on Anqi (Angie) Liu</title>
    <link>https://anqiliu-ai.github.io/</link>
    <description>Recent content in Anqi (Angie) Liu on Anqi (Angie) Liu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2022</copyright>
    <lastBuildDate>Tue, 05 Jul 2022 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Services</title>
      <link>https://anqiliu-ai.github.io/services/</link>
      <pubDate>Tue, 05 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://anqiliu-ai.github.io/services/</guid>
      <description>&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Teaching</title>
      <link>https://anqiliu-ai.github.io/teaching/</link>
      <pubDate>Tue, 05 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://anqiliu-ai.github.io/teaching/</guid>
      <description>&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Spring 2022: En.601.787 Machine Learning for Trustworthy AI. &lt;a href=&#34;https://anqiliu-ai.github.io/files/teaching/syllabus_trustworthy.pdf&#34;&gt;Syllabus&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Fall 2022: En.601.675(475) Machine Learning.&lt;/p&gt;

&lt;p&gt;Spring 2023: En.601.787 Machine Learning for Trustworthy AI.&lt;/p&gt;

&lt;p&gt;Spring 2024: En.601.675(475) Machine Learning.&lt;/p&gt;

&lt;p&gt;Fall 2024: En.601.787 Machine Learning for Trustworthy AI.&lt;/p&gt;

&lt;p&gt;Spring 2025: En.601.687(487) Machine Learning: Coping with Non-stationary Environments and Errors&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A list of past publications (By area), not updated frequently. Please refer to google scholar for most updated info.</title>
      <link>https://anqiliu-ai.github.io/publications/</link>
      <pubDate>Thu, 09 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://anqiliu-ai.github.io/publications/</guid>
      <description>&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&#34;font-size:larger;&#34;&gt;Distributionally Robust Learning (under data shifts):&lt;/space&gt;&lt;/p&gt;

&lt;p&gt;Haoxuan Wang, Anqi Liu, Zhiding Yu, Yisong Yue, and Anima Anandkumar. &amp;ldquo;&lt;a href=&#34;https://arxiv.org/pdf/2010.05784v1.pdf&#34; target=&#34;_blank&#34;&gt;Deep Distributionally Robust Learning for Calibrated Uncertainties under Domain Shift&lt;/a&gt;&amp;rdquo;, on Arxiv 2021.&lt;/p&gt;

&lt;p&gt;Rizal Fathony, Kaiser Asif, Anqi Liu, Mohammad Ali Bashiri, Wei Xing, Sima Behpour, Xinhua Zhang, and Brian D. Ziebart &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/1812.07526&#34; target=&#34;_blank&#34;&gt;Consistent Robust Adversarial Prediction for General Multiclass Classification&lt;/a&gt;&amp;rdquo;, On Arxiv 2018.&lt;/p&gt;

&lt;p&gt;Anqi Liu and Brian D. Ziebart &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/1712.10043&#34; target=&#34;_blank&#34;&gt;Robust Covariate Shift Prediction with General Losses and Feature Views&lt;/a&gt;&amp;rdquo;, On Arxiv 2017.&lt;/p&gt;

&lt;p&gt;Anqi Liu, Rizal Fathony, and Brian D. Ziebart &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/1712.10050&#34; target=&#34;_blank&#34;&gt;Kernel Robust Bias-Aware Prediction under Covariate Shift&lt;/a&gt;&amp;rdquo;, On Arxiv.&lt;/p&gt;

&lt;p&gt;Rizal Fathony, Anqi Liu, Kaiser Asif, and Brian D. Ziebart “&lt;a href=&#34;http://papers.nips.cc/paper/6088-adversarial-multiclass-classification-a-risk-minimization-perspective&#34; target=&#34;_blank&#34;&gt;Adversarial Multiclass Classification: A Risk Minimization Perspective&lt;/a&gt;”, In NeurIPS2016.&lt;/p&gt;

&lt;p&gt;Xiangli Chen, Mathew Monfort, Anqi Liu, and Brian D. Ziebart “&lt;a href=&#34;http://proceedings.mlr.press/v51/chen16d.pdf&#34; target=&#34;_blank&#34;&gt;Robust Covariate Shift Regression&lt;/a&gt;”, In AISTATS2016.&lt;/p&gt;

&lt;p&gt;Anqi Liu and Brian D. Ziebart “&lt;a href=&#34;http://papers.nips.cc/paper/5458-robust-classification-under-sample-selection-bias&#34; target=&#34;_blank&#34;&gt;Robust Classification under Sample Selection Bias&lt;/a&gt;”, In NeurIPS2014. Spotlight.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;br/&gt;
&lt;span style=&#34;font-size:larger;&#34;&gt;Active Learning (under data shifts):&lt;/space&gt;&lt;/p&gt;

&lt;p&gt;Eric Zhao, Anqi Liu, Anima Anandkumar, and Yisong Yue &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/2007.08479&#34; target=&#34;_blank&#34;&gt;Active Learning under Label Shift&lt;/a&gt;&amp;rdquo;, in AISTATS 2021.&lt;/p&gt;

&lt;p&gt;Sima Behpour, Anqi Liu, and Brian D. Ziebart &amp;ldquo;&lt;a href=&#34;http://proceedings.mlr.press/v97/behpour19a.html&#34; target=&#34;_blank&#34;&gt;Active Learning for Probabilistic Structured Prediction of Cuts and Matchings&lt;/a&gt;&amp;rdquo;, In ICML2019.&lt;/p&gt;

&lt;p&gt;Kamyar Azizzadenesheli, Anqi Liu, Fanny Yang, and Anima Anandkumar &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/1903.09734&#34; target=&#34;_blank&#34;&gt;Regularized Learning for Domain Adaptation under Label Shifts&lt;/a&gt;&amp;rdquo;, In ICLR2019.&lt;/p&gt;

&lt;p&gt;Anqi Liu, Lev Reyzin, and Brian D. Ziebart “&lt;a href=&#34;https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/viewPaper/9755&#34; target=&#34;_blank&#34;&gt;Shift-Pessimistic Active Learning using Robust Bias-Aware Prediction&lt;/a&gt;”, In AAAI2015.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;br/&gt;
&lt;span style=&#34;font-size:larger;&#34;&gt;Safe Decision Making (under data shifts):&lt;/space&gt;&lt;/p&gt;

&lt;p&gt;Hao Liu, Anima Anandkumar, Yisong Yue, and Anqi Liu. &amp;ldquo;Distributionally Robust Off-Policy Evaluation&amp;rdquo;, PDF coming soon.&lt;/p&gt;

&lt;p&gt;Yashwanth Kumar Nakka, Anqi Liu, Guanya Shi, Anima Anandkumar, Yisong Yue, and Soon-Jo Chung. &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/2005.04374&#34; target=&#34;_blank&#34;&gt;Chance-Constrained Trajectory Optimization for Safe Exploration and Learning of Nonlinear Systems&lt;/a&gt;&amp;rdquo;, RA-L, 2020.&lt;/p&gt;

&lt;p&gt;Anqi Liu, Guanya Shi, Soon-Jo Chung, Anima Anandkumar, and Yisong Yue &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/1906.05819&#34; target=&#34;_blank&#34;&gt;Robust Regression for Safe Exploration in Control&lt;/a&gt;&amp;rdquo;, In L4DC 2020.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;br/&gt;
&lt;span style=&#34;font-size:larger;&#34;&gt;Human Decision Making Modeling:&lt;/space&gt;&lt;/p&gt;

&lt;p&gt;Anqi Liu, Hao Liu, Tongxin Li, Saeed Karimi Bidhendi, Yisong Yue, and Anima Anandkumar &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/2101.06614&#34; target=&#34;_blank&#34;&gt;Disentangling Observed Causal Effects from Latent Confounders using Method of Moments&lt;/a&gt;&amp;rdquo;, on Arxiv 2021.&lt;/p&gt;

&lt;p&gt;Quanying Liu, Haiyan Wu, Anqi Liu &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/1906.05803&#34; target=&#34;_blank&#34;&gt;Modeling and Interpreting Real-world Human Risk Decision Making with Inverse Reinforcement Learning&lt;/a&gt;&amp;rdquo;, in Real-world Sequential Decision Making Workshop, ICML 2019.&lt;/p&gt;

&lt;p&gt;Mathew Monfort, Anqi Liu, and Brian D. Ziebart “&lt;a href=&#34;https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/viewPaper/9897&#34; target=&#34;_blank&#34;&gt;Trajectory Forecasting and Intent Recognition via Predictive Inverse Linear-Quadratic Regulation&lt;/a&gt;”, In AAAI2015.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;br/&gt;
&lt;span style=&#34;font-size:larger;&#34;&gt;Fair Machine Learning:&lt;/space&gt;&lt;/p&gt;

&lt;p&gt;Ashkan Rezaei, Anqi Liu, Omid Memarrast, and Brian D. Ziebart. &amp;ldquo;&lt;a href=&#34;https://arxiv.org/pdf/2010.05166.pdf&#34; target=&#34;_blank&#34;&gt;Robust Fairness Under Covariate Shift&lt;/a&gt;&amp;rdquo;, in AAAI 2021.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;br/&gt;
&lt;span style=&#34;font-size:larger;&#34;&gt;Computational Social Science/AI for Social Good:&lt;/space&gt;&lt;/p&gt;

&lt;p&gt;Maya Srikanth, Anqi Liu, Nicholas Adams-Cohen, Jian Cao, R Michael Alvarez, Anima Anandkumar &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/2102.12596&#34; target=&#34;_blank&#34;&gt;Dynamic Social Media Monitoring for Fast-Evolving Online Discussions&lt;/a&gt;&amp;rdquo;, In KDD ADS track, 2021.&lt;/p&gt;

&lt;p&gt;Anqi Liu, Maya Srikanth, Nicholas Adams-Cohen, R Michael Alvarez, Anima Anandkumar &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/1911.05332&#34; target=&#34;_blank&#34;&gt;Finding Social Media Trolls: Dynamic Keyword Selection Methods for Rapidly-Evolving Online Debates&lt;/a&gt;&amp;rdquo;, In AI for Social Good workshop at NeurIPS, 2019.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;br/&gt;
&lt;span style=&#34;font-size:larger;&#34;&gt;Text Mining/Information Retrieval:&lt;/space&gt;&lt;/p&gt;

&lt;p&gt;Hong Wang, Anqi Liu, Jing Wang, Brian D Ziebart, Clement T Yu, Warren Shen &amp;ldquo;&lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/2808194.2809453&#34; target=&#34;_blank&#34;&gt;Context Retrieval for Web Tables&lt;/a&gt;&amp;rdquo;, In International Conference on The Theory of Information Retrieval, 2015&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Students</title>
      <link>https://anqiliu-ai.github.io/students/</link>
      <pubDate>Thu, 09 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://anqiliu-ai.github.io/students/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;font-size:larger;&#34;&gt;Current students:&lt;/space&gt;&lt;/p&gt;

&lt;p&gt;PhD students:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://manhhabui.github.io/&#34; target=&#34;_blank&#34;&gt;Manh-Ha Bui&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.cs.jhu.edu/news/cs-undergrad-named-finalist-for-2022-cra-outstanding-undergraduate-researcher-award/&#34; target=&#34;_blank&#34;&gt;Sally Cao&lt;/a&gt; (co-advised with &lt;a href=&#34;https://www.cs.jhu.edu/~cmhuang/&#34; target=&#34;_blank&#34;&gt;Chien-Ming Huang&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/yihongguo/en&#34; target=&#34;_blank&#34;&gt;Yihong Guo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://zipjiang.github.io/&#34; target=&#34;_blank&#34;&gt;Zhengping Jiang&lt;/a&gt; (co-advised with &lt;a href=&#34;https://www.cs.jhu.edu/~vandurme/&#34; target=&#34;_blank&#34;&gt;Ben Van Durme&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aamixsh.github.io/&#34; target=&#34;_blank&#34;&gt;Aayush Mishra&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/drew-prinster&#34; target=&#34;_blank&#34;&gt;Drew Prinster&lt;/a&gt; (co-advised with &lt;a href=&#34;https://suchisaria.jhu.edu/&#34; target=&#34;_blank&#34;&gt;Suchi Saria&lt;/a&gt; and &lt;a href=&#34;https://www.cs.jhu.edu/~cmhuang/&#34; target=&#34;_blank&#34;&gt;Chien-Ming Huang&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://aiem.jhu.edu/people/gina-wong/&#34; target=&#34;_blank&#34;&gt;Gina Wong&lt;/a&gt; (co-advised with &lt;a href=&#34;https://engineering.jhu.edu/faculty/rama-chellappa/&#34; target=&#34;_blank&#34;&gt;Rama Chellappa&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://andreawynn.github.io/&#34; target=&#34;_blank&#34;&gt;Andrea Wynn&lt;/a&gt; (co-advised with &lt;a href=&#34;https://enalisnick.github.io/&#34; target=&#34;_blank&#34;&gt;Eric Nalisnick&lt;/a&gt;)&lt;/p&gt;

&lt;!-- I also (co-)mentor the following Master students:

Yihong Guo (Data Science)

Jiazhen Hu (CS)

Hyun Joo Rosalyn Shin (CS)

Yi Zhou (CS)
 --&gt;

&lt;p&gt;&lt;br&gt;
&lt;span style=&#34;font-size:larger;&#34;&gt;For prospective students:&lt;/space&gt;&lt;/p&gt;

&lt;p&gt;I am always looking for motivated students (PhD, master, and undergraduate) to join my group. To start doing research, here are some great advice from my colleagues: &lt;a href=&#34;https://www.cs.jhu.edu/~jason/advice/how-to-work-with-a-professor.html&#34; target=&#34;_blank&#34;&gt;For undergraduates and masters&lt;/a&gt; and &lt;a href=&#34;https://www.cs.jhu.edu/~mdredze/publications/HowtoBeaSuccessfulPhDStudent.1_1.pdf&#34; target=&#34;_blank&#34;&gt;How to be a successful PhD student&lt;/a&gt;.
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;If you are interested in working with me, please feel free to fill this form. &lt;a href=&#34;https://docs.google.com/forms/d/e/1FAIpQLSfP2r6zTildULt2K1pfX06A0PPeLitTSVBa-5gjukJwRR5x3Q/viewform?usp=sf_link&#34; target=&#34;_blank&#34;&gt;google form&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Distributionally Robust Learning under Covariate Shift</title>
      <link>https://anqiliu-ai.github.io/project/drl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://anqiliu-ai.github.io/project/drl/</guid>
      <description>&lt;p&gt;This project covers a series of my work, ranging from fundamentals of  distributionally robust learning under covariate shift, to its integration to real-world safe exploration and domain adaption tasks.&lt;/p&gt;

&lt;p&gt;Distributionally robust learning involves a minimax game between a predictor and an adversary, who is usually subject to constraints from data. Instead of focusing on the robustness against adversarial perturbations on the covariate variables, as in many recent literatures, I focus on using conditional output distributions as adversaries. This formulation has two major advantages: (1) It provides a conservative way to quantify the model uncertainties under covariate shift, which benefits data collection and experimental design on various real-world tasks. (2) It provides consistent predictors for minimizing non-smooth loss functions, which is usually elusive for the empirical risk minimization framework.&lt;/p&gt;

&lt;p&gt;Here are some featured papers in this line of work:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;In the vanilla supervised learning setting:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The first paper using logloss in the framework under covariate shift: the robust bias-aware classifier: Anqi Liu and Brian D. Ziebart “&lt;a href=&#34;http://papers.nips.cc/paper/5458-robust-classification-under-sample-selection-bias&#34; target=&#34;_blank&#34;&gt;Robust Classification under Sample Selection Bias&lt;/a&gt;”, In NeurIPS2014. Spotlight.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The first paper minimizing non-smooth loss function in this framework that provides consistent analytical solutions for minimax games under constraints: Rizal Fathony, Anqi Liu, Kaiser Asif, and Brian D. Ziebart “&lt;a href=&#34;http://papers.nips.cc/paper/6088-adversarial-multiclass-classification-a-risk-minimization-perspective&#34; target=&#34;_blank&#34;&gt;Adversarial Multiclass Classification: A Risk Minimization Perspective&lt;/a&gt;”, In NeurIPS2016.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The first paper solving regression problems in this framework under covariate shift that directly predicts Gaussian mean and variance for uncertainty estimation in continuous problems: Xiangli Chen, Mathew Monfort, Anqi Liu, and Brian D. Ziebart “&lt;a href=&#34;http://proceedings.mlr.press/v51/chen16d.pdf&#34; target=&#34;_blank&#34;&gt;Robust Covariate Shift Regression&lt;/a&gt;”, In AISTATS2016.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The first paper providing unified solutions for the framework under the general loss settings, like for cost-sensitive and abstaining loss functions:  Rizal Fathony, Kaiser Asif, Anqi Liu, Mohammad Ali Bashiri, Wei Xing, Sima Behpour, Xinhua Zhang, and Brian D. Ziebart &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/1812.07526&#34; target=&#34;_blank&#34;&gt;Consistent Robust Adversarial Prediction for General Multiclass Classification&lt;/a&gt;&amp;rdquo;, On Arxiv 2018.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Generalizing the weighting in the original formulation to more flexible weighting functions: Jose I. Segovia-Martin, Santiago Mazuelas, Anqi Liu. &amp;ldquo;&lt;a href=&#34;https://proceedings.mlr.press/v202/segovia-martin23a.html&#34; target=&#34;_blank&#34;&gt;Double-Weighting for Covariate Shift Adaptation&lt;/a&gt;&amp;rdquo;, in ICML2023.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;In the interactive learning setting:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The first paper tackling the sample bias problems in active learning from a robust learning point of view: Anqi Liu, Lev Reyzin, and Brian D. Ziebart “&lt;a href=&#34;https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/viewPaper/9755&#34; target=&#34;_blank&#34;&gt;Shift-Pessimistic Active Learning using Robust Bias-Aware Prediction&lt;/a&gt;”, In AAAI2015.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The first paper integrating the conservative uncertainty quantification to help improve safe exploration efficiency and constraint satisfaction in real-world systems: Anqi Liu, Guanya Shi, Soon-Jo Chung, Anima Anandkumar, and Yisong Yue &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/1906.05819&#34; target=&#34;_blank&#34;&gt;Robust Regression for Safe Exploration in Control&lt;/a&gt;&amp;rdquo;, In L4DC 2020.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The first paper providing robust dynamics estimation and end-to-end guarantees for safe planning in stochastic control systems:
Yashwanth Kumar Nakka, Anqi Liu, Guanya Shi, Anima Anandkumar, Yisong Yue, and Soon-Jo Chung. &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/2005.04374&#34; target=&#34;_blank&#34;&gt;Chance-Constrained Trajectory Optimization for Safe Exploration and Learning of Nonlinear Systems&lt;/a&gt;&amp;rdquo;, RA-L, 2020.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;In the fair learning setting:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The first paper dealing with the intersection between covariate shift and fairness from a robust learning point of view: Ashkan Rezaei, Anqi Liu, Omid Memarrast, and Brian D. Ziebart. &amp;ldquo;&lt;a href=&#34;https://arxiv.org/pdf/2010.05166.pdf&#34; target=&#34;_blank&#34;&gt;Robust Fairness Under Covariate Shift&lt;/a&gt;&amp;rdquo;, AAAI2021.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;In the large-scale deep learning setting:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The first paper scaling up the distributionally robust learning under covariate shift to solve large scale sim-to-real unsupervised domain adaptation tasks: Haoxuan Wang, Zhiding Yu, Yisong Yue, and Anima Anandkumar, Anqi Liu, Junchi Yan. &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/2010.05784&#34; target=&#34;_blank&#34;&gt;Learning Calibrated Uncertainties for Domain Shift: A Distributionally Robust Learning Approach&lt;/a&gt;&amp;rdquo;, in IJCAI 2023.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Motivating calibrated uncertainty estimation for deep classification under distribution shifts: &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/2302.06495&#34; target=&#34;_blank&#34;&gt;Density-Softmax: Scalable and Calibrated Uncertainty Estimation under Distribution Shifts&lt;/a&gt;&amp;rdquo;, on ArXiv 2023.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Motivating calibrated uncertainty estimation for deep regression under distribution shifts: Ha Manh Bui, Anqi Liu. &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/2403.05600&#34; target=&#34;_blank&#34;&gt;Density-Regression: Efficient and Distance-Aware Deep Regressor for Uncertainty Estimation under Distribution Shifts&lt;/a&gt;&amp;rdquo;, in AISTATS2024&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;In offline policy evaluation and learning setting in contextual bandits:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The first paper taking a covariate shift regression point of view to deal with offline policy learning in contextual bandits: Zhouhao Yang, Yihong Guo, Pan Xu, Anqi Liu, Animashree Anandkumar. &amp;ldquo;&lt;a href=&#34;https://proceedings.mlr.press/v206/yang23f.html&#34; target=&#34;_blank&#34;&gt;Distributionally Robust Policy Gradient for Offline Contextual Bandits&lt;/a&gt;&amp;rdquo;, in AISTATS2023.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>UQ for AI Safety and Fairness</title>
      <link>https://anqiliu-ai.github.io/project/social/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://anqiliu-ai.github.io/project/social/</guid>
      <description>&lt;p&gt;This project covers a series of my work on uncertainty quantification under distribution shift, especially covariate shift. We look at various metrics to evaluate the quality of uncertainty estimates, ranging from marginal coverage, sharpness, to expected calibration errors (for subgroups). We aim to develop rigorous and principled methods that is also practical in real world applications. For example, we try to improve and better balance the sample complexity and computational complexity for popular distributon-free methods like conformal predictions. We also utilize data beyond traditional labeled data in supervised learning for the purpose of model calibration. For example, we leverage human annotation to &amp;ldquo;align&amp;rdquo; the LLM better with human uncertainty.&lt;/p&gt;

&lt;p&gt;Here are some featured papers in this line of work:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A series of wrapper methods for distribution-free uncertainty quantification tasks under covariate shift, utilizing the more sample efficient jackknife+ methods: Andrew Prinster, Anqi Liu, Suchi Saria. &amp;ldquo;&lt;a href=&#34;https://proceedings.neurips.cc/paper_files/paper/2022/file/e944bacecce6b06374ac39b260348db0-Paper-Conference.pdf&#34; target=&#34;_blank&#34;&gt;JAWS: Auditing Predictive Uncertainty Under Covariate Shift&lt;/a&gt;&amp;rdquo;, in NeurIPS 2022.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A collection of methods based on the jackknife+ that achieve a practical balance of computational and statistical efficiency: Drew Prinster, Suchi Saria, Anqi Liu. &amp;ldquo;&lt;a href=&#34;https://proceedings.mlr.press/v202/prinster23a.html&#34; target=&#34;_blank&#34;&gt;JAWS-X: Addressing Efficiency Bottlenecks of Conformal Prediction Under Standard and Feedback Covariate Shift&lt;/a&gt;&amp;rdquo;, in ICML 2023.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Calibrated and efficient uncertainty estimation for deep classification under distribution shifts: &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/2302.06495&#34; target=&#34;_blank&#34;&gt;Density-Softmax: Scalable and Calibrated Uncertainty Estimation under Distribution Shifts&lt;/a&gt;&amp;rdquo;, on ArXiv 2023.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Calibrated and efficient uncertainty estimation for deep regression under distribution shifts: Ha Manh Bui, Anqi Liu. &amp;ldquo;&lt;a href=&#34;https://arxiv.org/abs/2403.05600&#34; target=&#34;_blank&#34;&gt;Density-Regression: Efficient and Distance-Aware Deep Regressor for Uncertainty Estimation under Distribution Shifts&lt;/a&gt;&amp;rdquo;, in AISTATS2024&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Calibrating pre-trained large language models in cross-lingual tasks: Zhengping Jiang, Anqi Liu, Benjamin Van Durme. &amp;ldquo;&lt;a href=&#34;https://aclanthology.org/2022.emnlp-main.170/&#34; target=&#34;_blank&#34;&gt;Calibrating Zero-shot Cross-lingual (Un-)structured Predictions&lt;/a&gt;&amp;rdquo;, in EMNLP2022.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Human scalar annotation for better calibrating large language models: Zhengping Jiang, Anqi Liu, Benjamnin Van Durme. &lt;a href=&#34;https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00636/119541&#34; target=&#34;_blank&#34;&gt;Addressing the Binning Problem in Calibration Assessment through Scalar Annotations&lt;/a&gt;, in TACL 2024.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- 

+++
# Date this page was created.


# Project title.
title = &#34;Trustworthy Social Media&#34;

# Project summary to display on homepage.
summary = &#34;We aim to use AI techniques for building a more trustworthy social media. We work on online trolling detection, public discussion monitoring, social network analysis, and so on. Media Coverage: [AI for #MeToo](https://www.caltech.edu/about/news/ai-metoo-training-algorithms-spot-online-trolls).&#34;

# Optional image to display on homepage (relative to `static/img/` folder).
#image_preview = &#34;bubbles.jpg&#34;

# Tags: can be used for filtering projects.
# Example: `tags = [&#34;machine-learning&#34;, &#34;deep-learning&#34;]`
#tags = [&#34;Trustworthy Social Media&#34;]

# Optional external URL for project (replaces project detail page).
external_link = &#34;&#34;

# Does the project detail page use math formatting?
math = false

# Optional featured image (relative to `static/img/` folder).
#[header]
#image = &#34;headers/bubbles-wide.jpg&#34;
#caption = &#34;My caption 😄&#34;

+++

This project is a collaboration between machine learning researchers and social scientists. It is a joint effort by a group of undergraduates, graduate students, postdocs, and professors. Meet our team members [here](#contributors)! Check our medium posts for further reading [here](https://medium.com/trustworthy-social-media)!

We aim to use AI techniques for building a more trustworthy social media. We work on online trolling detection, public discussion monitoring, social network analysis, and so on. Our research asks: *what a healthier public communication environment would be like in this era? And how can machine learning help?*

We are supported by various funding resources, including [NSF](https://www.nsf.gov/awardsearch/showAward?AWD_ID=2126095&amp;HistoricalAwards=false). We are also collaborating with industry partners, including Google, Twitter, Nvidia and Oracle. 

Here are some featured projects:

* Understanding the prominent #metoo movement: What are people talking about and how are different topics discussed?

    * A word-embedding approach to discover new keywords for dynamic data collection with applications on multiple topics and discussion space: 

        * [Finding Social Media Trolls: Dynamic Keyword Selection Methods for Rapidly-Evolving Online Debates](/files/social_projects/NeurIPS2019TwitterPosterOfficial.pdf). In Neurips workshp: AI for Social Good, 2019. [Paper](https://arxiv.org/abs/1911.05332)

        * [Tracking Social Media Movements with Dynamic Keyword Algorithm](/files/social_projects/polmeth.pdf). In American Political Science Association Annal Meeting and Exhibition, 2020.

        * [Dynamic Algorithms for Social Medial Troll Detection](/files/social_projects/wiml_maya.png). In ICML WIML Un-Workshop, 2020.

        * [Dynamic Social Media Monitoring for Fast-Evolving Online Discussions](https://arxiv.org/abs/2102.12596). Presented at the SIGKDD 2021 Applied Data Science Track. [Paper](https://dl.acm.org/doi/abs/10.1145/3447548.3467171) [Poster](/files/social_projects/2923.SrikanthM.pdf) [Video](https://drive.google.com/file/d/1coFJwZaMjyzBLdgN9BHQwg6Mh78mu00a/view?usp=sharing)

    * A topic modeling method for capturing topic distributions and keywords that reveals how #MeToo got viral in 2017: [Understanding the Evolution of the #MeToo Movement Over Time Using Topic Models](/files/social_projects/wiml.png). In ICML WIML Un-Workshop, 2020. [Presentation](https://www.youtube.com/watch?v=yMk6rAHXK04)

* A technical report on how to collect data for online discussions monitoring: [Reliable and Efficient Long-Term Social Media Monitoring](https://arxiv.org/abs/2005.02442v2). Under review. 

* An analysis of leadership and communication dynamics between politic figures using social media data and NLP approaches: [Legislative Communication and Power: Measuring Leadership from Social Media Data](https://drive.google.com/file/d/10BUe9Gb4UV_r8fATn1xZibZQlrV7JVsJ/view?usp=sharing).

* Understanding what has been discussed on social media during COVID-19: [Collecting, Preprocessing, and Analyzing Large-Scale Social Media Data: COVID-19 Case Study](https://www.youtube.com/watch?v=TBtX4dUMLKo). Presented at the CloudBank RRoCCET21 conference. [Slides](/files/social_projects/COVID_CloudBank_presentation_final.pdf)


&lt;!-- 2.Understanding the Anti-Asian sentiment during the COVID-19 pandemic: --&gt;

&lt;!-- Contributors&lt;a name=&#34;contributors&#34;&gt;&lt;/a&gt;: 

* PIs: [Mike Alvarez (Caltech)](https://www.hss.caltech.edu/people/r-m-michael-alvarez), [Anima Anandkumar (Caltech)](http://tensorlab.cms.caltech.edu/users/anima/), [Anqi Liu (JHU)](https://anqiliu-ai.github.io/)

* Postdocs: [Jian Cao](https://www.hss.caltech.edu/people/jian-cao), [Rafał Kocielnik](https://rkocielnik.com/)

* Graduate Students: [Danny Ebanks](https://www.linkedin.com/in/daniel-ebanks-9b89a298), [Jacob Morrier](https://www.hss.caltech.edu/people/jacob-morrier), [Zhuofang Li](https://www.hss.caltech.edu/people/zhuofang-li), [Claudia Kann](https://www.hss.caltech.edu/people/claudia-kann), [Md. Yasin Kabir](https://scholar.google.com/citations?user=nm9qB7kAAAAJ&amp;hl=en)
 

* Undergraduate Students: [Sara Kangaslahti](https://www.linkedin.com/in/sara-kangaslahti), [Sarah Hashash](https://www.linkedin.com/in/sarah-hashash-65603a1a7)

* Industry Collaborators: [Jean Kossaifi](http://jeankossaifi.com/), [Bojan Tunguz](https://www.linkedin.com/in/tunguz)

* Past students and postdocs: 
    * [Nicholas Adams-Cohen](https://www.nadamscohen.com/), Now researcher at Accenture

    * [Maya Srikanth](https://www.linkedin.com/in/maya-s-srikanth), Now graduate student at Stanford

    * [Shunto J. Kobayashi](https://www.linkedin.com/in/shunto-kobayashi-323015113)
    * [Shiyu Zhang](https://www.linkedin.com/in/shiyu-zhang-1783608b)



 --&gt;
</description>
    </item>
    
  </channel>
</rss>
