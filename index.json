[
  {
    "authors": null,
    "categories": null,
    "content": "\n\n",
    "date": 1656979200,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1656979200,
    "objectID": "bfc9941b6b6fd7b4ef09dd0ccd08af0c",
    "permalink": "https://anqiliu-ai.github.io/services/",
    "publishdate": "2022-07-05T00:00:00Z",
    "relpermalink": "/services/",
    "section": "",
    "summary": "",
    "tags": null,
    "title": "Services",
    "type": "page"
  },
  {
    "authors": null,
    "categories": null,
    "content": "\nSpring 2022: En.601.787 Machine Learning for Trustworthy AI. Syllabus\nFall 2022: En.601.675(475) Machine Learning.\nSpring 2023: En.601.787 Machine Learning for Trustworthy AI.\nSpring 2024: En.601.675(475) Machine Learning.\n\n",
    "date": 1656979200,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1656979200,
    "objectID": "416f445d9bade50adf875443b512ceeb",
    "permalink": "https://anqiliu-ai.github.io/teaching/",
    "publishdate": "2022-07-05T00:00:00Z",
    "relpermalink": "/teaching/",
    "section": "",
    "summary": "Spring 2022: En.601.787 Machine Learning for Trustworthy AI. Syllabus\nFall 2022: En.601.675(475) Machine Learning.\nSpring 2023: En.601.787 Machine Learning for Trustworthy AI.\nSpring 2024: En.601.675(475) Machine Learning.",
    "tags": null,
    "title": "Teaching",
    "type": "page"
  },
  {
    "authors": null,
    "categories": null,
    "content": "\nDistributionally Robust Learning (under data shifts):\nHaoxuan Wang, Anqi Liu, Zhiding Yu, Yisong Yue, and Anima Anandkumar. \u0026ldquo;Deep Distributionally Robust Learning for Calibrated Uncertainties under Domain Shift\u0026rdquo;, on Arxiv 2021.\nRizal Fathony, Kaiser Asif, Anqi Liu, Mohammad Ali Bashiri, Wei Xing, Sima Behpour, Xinhua Zhang, and Brian D. Ziebart \u0026ldquo;Consistent Robust Adversarial Prediction for General Multiclass Classification\u0026rdquo;, On Arxiv 2018.\nAnqi Liu and Brian D. Ziebart \u0026ldquo;Robust Covariate Shift Prediction with General Losses and Feature Views\u0026rdquo;, On Arxiv 2017.\nAnqi Liu, Rizal Fathony, and Brian D. Ziebart \u0026ldquo;Kernel Robust Bias-Aware Prediction under Covariate Shift\u0026rdquo;, On Arxiv.\nRizal Fathony, Anqi Liu, Kaiser Asif, and Brian D. Ziebart “Adversarial Multiclass Classification: A Risk Minimization Perspective”, In NeurIPS2016.\nXiangli Chen, Mathew Monfort, Anqi Liu, and Brian D. Ziebart “Robust Covariate Shift Regression”, In AISTATS2016.\nAnqi Liu and Brian D. Ziebart “Robust Classification under Sample Selection Bias”, In NeurIPS2014. Spotlight.\n Active Learning (under data shifts):\nEric Zhao, Anqi Liu, Anima Anandkumar, and Yisong Yue \u0026ldquo;Active Learning under Label Shift\u0026rdquo;, in AISTATS 2021.\nSima Behpour, Anqi Liu, and Brian D. Ziebart \u0026ldquo;Active Learning for Probabilistic Structured Prediction of Cuts and Matchings\u0026rdquo;, In ICML2019.\nKamyar Azizzadenesheli, Anqi Liu, Fanny Yang, and Anima Anandkumar \u0026ldquo;Regularized Learning for Domain Adaptation under Label Shifts\u0026rdquo;, In ICLR2019.\nAnqi Liu, Lev Reyzin, and Brian D. Ziebart “Shift-Pessimistic Active Learning using Robust Bias-Aware Prediction”, In AAAI2015.\n Safe Decision Making (under data shifts):\nHao Liu, Anima Anandkumar, Yisong Yue, and Anqi Liu. \u0026ldquo;Distributionally Robust Off-Policy Evaluation\u0026rdquo;, PDF coming soon.\nYashwanth Kumar Nakka, Anqi Liu, Guanya Shi, Anima Anandkumar, Yisong Yue, and Soon-Jo Chung. \u0026ldquo;Chance-Constrained Trajectory Optimization for Safe Exploration and Learning of Nonlinear Systems\u0026rdquo;, RA-L, 2020.\nAnqi Liu, Guanya Shi, Soon-Jo Chung, Anima Anandkumar, and Yisong Yue \u0026ldquo;Robust Regression for Safe Exploration in Control\u0026rdquo;, In L4DC 2020.\n Human Decision Making Modeling:\nAnqi Liu, Hao Liu, Tongxin Li, Saeed Karimi Bidhendi, Yisong Yue, and Anima Anandkumar \u0026ldquo;Disentangling Observed Causal Effects from Latent Confounders using Method of Moments\u0026rdquo;, on Arxiv 2021.\nQuanying Liu, Haiyan Wu, Anqi Liu \u0026ldquo;Modeling and Interpreting Real-world Human Risk Decision Making with Inverse Reinforcement Learning\u0026rdquo;, in Real-world Sequential Decision Making Workshop, ICML 2019.\nMathew Monfort, Anqi Liu, and Brian D. Ziebart “Trajectory Forecasting and Intent Recognition via Predictive Inverse Linear-Quadratic Regulation”, In AAAI2015.\n Fair Machine Learning:\nAshkan Rezaei, Anqi Liu, Omid Memarrast, and Brian D. Ziebart. \u0026ldquo;Robust Fairness Under Covariate Shift\u0026rdquo;, in AAAI 2021.\n Computational Social Science/AI for Social Good:\nMaya Srikanth, Anqi Liu, Nicholas Adams-Cohen, Jian Cao, R Michael Alvarez, Anima Anandkumar \u0026ldquo;Dynamic Social Media Monitoring for Fast-Evolving Online Discussions\u0026rdquo;, In KDD ADS track, 2021.\nAnqi Liu, Maya Srikanth, Nicholas Adams-Cohen, R Michael Alvarez, Anima Anandkumar \u0026ldquo;Finding Social Media Trolls: Dynamic Keyword Selection Methods for Rapidly-Evolving Online Debates\u0026rdquo;, In AI for Social Good workshop at NeurIPS, 2019.\n Text Mining/Information Retrieval:\nHong Wang, Anqi Liu, Jing Wang, Brian D Ziebart, Clement T Yu, Warren Shen \u0026ldquo;Context Retrieval for Web Tables\u0026rdquo;, In International Conference on The Theory of Information Retrieval, 2015\n\n",
    "date": 1631145600,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1631145600,
    "objectID": "480c4de99851329b51acecc000e2e84f",
    "permalink": "https://anqiliu-ai.github.io/publications/",
    "publishdate": "2021-09-09T00:00:00Z",
    "relpermalink": "/publications/",
    "section": "",
    "summary": "Distributionally Robust Learning (under data shifts):\nHaoxuan Wang, Anqi Liu, Zhiding Yu, Yisong Yue, and Anima Anandkumar. \u0026ldquo;Deep Distributionally Robust Learning for Calibrated Uncertainties under Domain Shift\u0026rdquo;, on Arxiv 2021.\nRizal Fathony, Kaiser Asif, Anqi Liu, Mohammad Ali Bashiri, Wei Xing, Sima Behpour, Xinhua Zhang, and Brian D. Ziebart \u0026ldquo;Consistent Robust Adversarial Prediction for General Multiclass Classification\u0026rdquo;, On Arxiv 2018.\nAnqi Liu and Brian D. Ziebart \u0026ldquo;Robust Covariate Shift Prediction with General Losses and Feature Views\u0026rdquo;, On Arxiv 2017.",
    "tags": null,
    "title": "A list of past publications (By area), not updated frequently. Please refer to google scholar for most updated info.",
    "type": "page"
  },
  {
    "authors": null,
    "categories": null,
    "content": "Current students:\nPhD students:\nManh-Ha Bui\nIliana Maifeld-Carucci (co-advised with I-Jeng Wang)\nSally Cao (co-advised with Chien-Ming Huang)\nYihong Guo\nZhengping Jiang (co-advised with Ben Van Durme)\nAayush Mishra\nDrew Prinster (co-advised with Suchi Saria and Chien-Ming Huang)\nGina Wong (co-advised with Rama Chellappa)\n\nFor prospective students:\nI am always looking for motivated students (PhD, master, and undergraduate) to join my group. To start doing research, here are some great advice from my colleagues: For undergraduates and masters and How to be a successful PhD student. If you are interested in working with me, please feel free to fill this form. google form\n",
    "date": 1631145600,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": 1631145600,
    "objectID": "de354e522e3337061ca4d76bfdd32d47",
    "permalink": "https://anqiliu-ai.github.io/students/",
    "publishdate": "2021-09-09T00:00:00Z",
    "relpermalink": "/students/",
    "section": "",
    "summary": "Current students:\nPhD students:\nManh-Ha Bui\nIliana Maifeld-Carucci (co-advised with I-Jeng Wang)\nSally Cao (co-advised with Chien-Ming Huang)\nYihong Guo\nZhengping Jiang (co-advised with Ben Van Durme)\nAayush Mishra\nDrew Prinster (co-advised with Suchi Saria and Chien-Ming Huang)\nGina Wong (co-advised with Rama Chellappa)\n\nFor prospective students:\nI am always looking for motivated students (PhD, master, and undergraduate) to join my group. To start doing research, here are some great advice from my colleagues: For undergraduates and masters and How to be a successful PhD student.",
    "tags": null,
    "title": "Students",
    "type": "page"
  },
  {
    "authors": null,
    "categories": null,
    "content": "This project covers a series of my work, ranging from fundamentals of distributionally robust learning under covariate shift, to its integration to real-world safe exploration and domain adaption tasks.\nDistributionally robust learning involves a minimax game between a predictor and an adversary, who is usually subject to constraints from data. Instead of focusing on the robustness against adversarial perturbations on the covariate variables, as in many recent literatures, I focus on using conditional output distributions as adversaries. This formulation has two major advantages: (1) It provides a conservative way to quantify the model uncertainties under covariate shift, which benefits data collection and experimental design on various real-world tasks. (2) It provides consistent predictors for minimizing non-smooth loss functions, which is usually elusive for the empirical risk minimization framework.\nHere are some featured papers in this line of work:\n In the vanilla supervised learning setting:\n The first paper using logloss in the framework under covariate shift: the robust bias-aware classifier: Anqi Liu and Brian D. Ziebart “Robust Classification under Sample Selection Bias”, In NeurIPS2014. Spotlight.\n The first paper minimizing non-smooth loss function in this framework that provides consistent analytical solutions for minimax games under constraints: Rizal Fathony, Anqi Liu, Kaiser Asif, and Brian D. Ziebart “Adversarial Multiclass Classification: A Risk Minimization Perspective”, In NeurIPS2016.\n The first paper solving regression problems in this framework under covariate shift that directly predicts Gaussian mean and variance for uncertainty estimation in continuous problems: Xiangli Chen, Mathew Monfort, Anqi Liu, and Brian D. Ziebart “Robust Covariate Shift Regression”, In AISTATS2016.\n The first paper providing unified solutions for the framework under the general loss settings, like for cost-sensitive and abstaining loss functions: Rizal Fathony, Kaiser Asif, Anqi Liu, Mohammad Ali Bashiri, Wei Xing, Sima Behpour, Xinhua Zhang, and Brian D. Ziebart \u0026ldquo;Consistent Robust Adversarial Prediction for General Multiclass Classification\u0026rdquo;, On Arxiv 2018.\n  In the interactive learning setting:\n The first paper tackling the sample bias problems in active learning from a robust learning point of view: Anqi Liu, Lev Reyzin, and Brian D. Ziebart “Shift-Pessimistic Active Learning using Robust Bias-Aware Prediction”, In AAAI2015.\n The first paper integrating the conservative uncertainty quantification to help improve safe exploration efficiency and constraint satisfaction in real-world systems: Anqi Liu, Guanya Shi, Soon-Jo Chung, Anima Anandkumar, and Yisong Yue \u0026ldquo;Robust Regression for Safe Exploration in Control\u0026rdquo;, In L4DC 2020.\n The first paper providing robust dynamics estimation and end-to-end guarantees for safe planning in stochastic control systems: Yashwanth Kumar Nakka, Anqi Liu, Guanya Shi, Anima Anandkumar, Yisong Yue, and Soon-Jo Chung. \u0026ldquo;Chance-Constrained Trajectory Optimization for Safe Exploration and Learning of Nonlinear Systems\u0026rdquo;, RA-L, 2020.\n  In the large-scale learning setting:\n The first paper scaling up the distributionally robust learning under covariate shift to solve large scale sim-to-real unsupervised domain adaptation tasks: Haoxuan Wang, Anqi Liu, Zhiding Yu, Yisong Yue, and Anima Anandkumar. \u0026ldquo;Distributionally Robust Learning for Unsupervised Domain Adaptation\u0026rdquo;, on Arxiv 2020.  In the fair learning setting:\n The first paper dealing with the intersection between covariate shift and fairness from a robust learning point of view: Ashkan Rezaei, Anqi Liu, Omid Memarrast, and Brian D. Ziebart. \u0026ldquo;Robust Fairness Under Covariate Shift\u0026rdquo;, AAAI2021.   ",
    "date": -62135596800,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": -62135596800,
    "objectID": "8b5b65047e904440b04afb4d43e8cac8",
    "permalink": "https://anqiliu-ai.github.io/project/drl/",
    "publishdate": "0001-01-01T00:00:00Z",
    "relpermalink": "/project/drl/",
    "section": "project",
    "summary": "This project covers a series of my work, ranging from fundamentals of  distributionally robust learning under covariate shift, to its integration to real-world safe exploration and domain adaption tasks. Media Coverage: [The Value of Saying ‘I Don’t Know’](https://engineering.uic.edu/about/coe-news/rise/rise/the-value-of-saying-i-dont-know/).",
    "tags": null,
    "title": "Distributionally Robust Learning under Covariate Shift",
    "type": "project"
  },
  {
    "authors": null,
    "categories": null,
    "content": "This project is a collaboration between machine learning researchers and social scientists. It is a joint effort by a group of undergraduates, graduate students, postdocs, and professors. Meet our team members here! Check our medium posts for further reading here!\nWe aim to use AI techniques for building a more trustworthy social media. We work on online trolling detection, public discussion monitoring, social network analysis, and so on. Our research asks: what a healthier public communication environment would be like in this era? And how can machine learning help?\nWe are supported by various funding resources, including NSF. We are also collaborating with industry partners, including Google, Twitter, Nvidia and Oracle.\nHere are some featured projects:\n Understanding the prominent #metoo movement: What are people talking about and how are different topics discussed?\n A word-embedding approach to discover new keywords for dynamic data collection with applications on multiple topics and discussion space:\n Finding Social Media Trolls: Dynamic Keyword Selection Methods for Rapidly-Evolving Online Debates. In Neurips workshp: AI for Social Good, 2019. Paper\n Tracking Social Media Movements with Dynamic Keyword Algorithm. In American Political Science Association Annal Meeting and Exhibition, 2020.\n Dynamic Algorithms for Social Medial Troll Detection. In ICML WIML Un-Workshop, 2020.\n Dynamic Social Media Monitoring for Fast-Evolving Online Discussions. Presented at the SIGKDD 2021 Applied Data Science Track. Paper Poster Video\n  A topic modeling method for capturing topic distributions and keywords that reveals how #MeToo got viral in 2017: Understanding the Evolution of the #MeToo Movement Over Time Using Topic Models. In ICML WIML Un-Workshop, 2020. Presentation\n  A technical report on how to collect data for online discussions monitoring: Reliable and Efficient Long-Term Social Media Monitoring. Under review.\n An analysis of leadership and communication dynamics between politic figures using social media data and NLP approaches: Legislative Communication and Power: Measuring Leadership from Social Media Data.\n Understanding what has been discussed on social media during COVID-19: Collecting, Preprocessing, and Analyzing Large-Scale Social Media Data: COVID-19 Case Study. Presented at the CloudBank RRoCCET21 conference. Slides\n  Contributors:\n PIs: Mike Alvarez (Caltech), Anima Anandkumar (Caltech), Anqi Liu (JHU)\n Postdocs: Jian Cao, Rafał Kocielnik\n Graduate Students: Danny Ebanks, Jacob Morrier, Zhuofang Li, Claudia Kann, Md. Yasin Kabir\n Undergraduate Students: Sara Kangaslahti, Sarah Hashash\n Industry Collaborators: Jean Kossaifi, Bojan Tunguz\n Past students and postdocs:\n Nicholas Adams-Cohen, Now researcher at Accenture\n Maya Srikanth, Now graduate student at Stanford\n Shunto J. Kobayashi\n Shiyu Zhang\n   ",
    "date": -62135596800,
    "expirydate": -62135596800,
    "kind": "page",
    "lang": "en",
    "lastmod": -62135596800,
    "objectID": "e38e9e1fe5b538cfacdd7de7fbfbd5b2",
    "permalink": "https://anqiliu-ai.github.io/project/social/",
    "publishdate": "0001-01-01T00:00:00Z",
    "relpermalink": "/project/social/",
    "section": "project",
    "summary": "We aim to use AI techniques for building a more trustworthy social media. We work on online trolling detection, public discussion monitoring, social network analysis, and so on. Media Coverage: [AI for #MeToo](https://www.caltech.edu/about/news/ai-metoo-training-algorithms-spot-online-trolls).",
    "tags": null,
    "title": "Trustworthy Social Media",
    "type": "project"
  }
]